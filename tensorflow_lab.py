# -*- coding: utf-8 -*-
"""TensorFlow_Lab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eTZ0NLW6qejCOJG3AzzkNBmL0o9Fe80Y
"""

import tensorflow as tf
print("TensorFlow version:", tf.__version__)

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

x_train, x_test = x_train / 255.0, x_test / 255.0

import matplotlib.pyplot as plt
plt.imshow(x_train[0], cmap='gray')
plt.title("Label: " + str(y_train[0]))
plt.show()

model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)

test_loss, test_accuracy = model.evaluate(x_test, y_test)
print("Test accuracy:", test_accuracy)

predictions = model.predict(x_test)

plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i + 1)
    plt.imshow(x_test[i], cmap='gray')
    plt.title(f"True: {y_test[i]}, Predicted: {tf.argmax(predictions[i])}")
    plt.axis('off')
plt.show()

"""Zadanie na ocene 1"""

model_3epochs = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

model_3epochs.compile(optimizer='adam',
                      loss='sparse_categorical_crossentropy',
                      metrics=['accuracy'])

print("Trening z 3 epokami")
model_3epochs.fit(x_train, y_train, epochs=3, verbose=1)

test_loss_3, test_accuracy_3 = model_3epochs.evaluate(x_test, y_test)
print(f"\nDokładność z 3 epokami: {test_accuracy_3:.4f}")

model_10epochs = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

model_10epochs.compile(optimizer='adam',
                       loss='sparse_categorical_crossentropy',
                       metrics=['accuracy'])

print("Trening z 10 epokami")
model_10epochs.fit(x_train, y_train, epochs=10, verbose=1)

test_loss_10, test_accuracy_10 = model_10epochs.evaluate(x_test, y_test)
print(f"\nDokładność z 10 epokami: {test_accuracy_10:.4f}")

print("Porównanie")
print(f"3 epoki:  {test_accuracy_3:.4f}")
print(f"5 epok:   {test_accuracy:.4f}")
print(f"10 epok:  {test_accuracy_10:.4f}")

"""Zadanie 2"""

# model z 2 warstwami ukrytymi
model_2layers = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

model_2layers.compile(optimizer='adam',
                      loss='sparse_categorical_crossentropy',
                      metrics=['accuracy'])

#
print("Model z 2 warstwami ukrytymi")
model_2layers.fit(x_train, y_train, epochs=5, verbose=1)

test_loss_2layers, test_accuracy_2layers = model_2layers.evaluate(x_test, y_test)
print(f"\nDokładność z 2 warstwami: {test_accuracy_2layers:.4f}")

model_3layers = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

model_3layers.compile(optimizer='adam',
                      loss='sparse_categorical_crossentropy',
                      metrics=['accuracy'])

print("Model z 3 warstwami ukrytymi")
model_3layers.fit(x_train, y_train, epochs=5, verbose=1)

test_loss_3layers, test_accuracy_3layers = model_3layers.evaluate(x_test, y_test)
print(f"\nDokładność z 3 warstwami: {test_accuracy_3layers:.4f}")

print("Porównanie")
print(f"1 warstwa ukryta:  {test_accuracy:.4f}")
print(f"2 warstwy ukryte:  {test_accuracy_2layers:.4f}")
print(f"3 warstwy ukryte:  {test_accuracy_3layers:.4f}")

"""Zadanie 3"""

# Model z 64 neuronami
model_64neurons = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

model_64neurons.compile(optimizer='adam',
                        loss='sparse_categorical_crossentropy',
                        metrics=['accuracy'])

print("Model z 64 neuronami")
model_64neurons.fit(x_train, y_train, epochs=5, verbose=1)

test_loss_64, test_accuracy_64 = model_64neurons.evaluate(x_test, y_test)
print(f"\nDokładność z 64 neuronami: {test_accuracy_64:.4f}")

model_256neurons = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

model_256neurons.compile(optimizer='adam',
                         loss='sparse_categorical_crossentropy',
                         metrics=['accuracy'])

print("Model z 256 neuronami")
model_256neurons.fit(x_train, y_train, epochs=5, verbose=1)

test_loss_256, test_accuracy_256 = model_256neurons.evaluate(x_test, y_test)
print(f"\nDokładność z 256 neuronami: {test_accuracy_256:.4f}")

print("Porównanie")
print(f"64 neurony:   {test_accuracy_64:.4f}")
print(f"128 neuronów: {test_accuracy:.4f}")
print(f"256 neuronów: {test_accuracy_256:.4f}")

"""Zadanie 4"""

import numpy as np

predictions = model.predict(x_test)
predicted_labels = np.argmax(predictions, axis=1)

print("dokładność dla każdej cyfry\n")

for digit in range(10):
    mask = (y_test == digit)

    correct = np.sum(predicted_labels[mask] == digit)
    total = np.sum(mask)
    accuracy = correct / total

    print(f"Cyfra {digit}: {accuracy:.4f} ({correct}/{total} poprawnych)")

incorrect_indices = np.where(predicted_labels != y_test)[0]

print(f"\nLiczba błędów: {len(incorrect_indices)} z {len(y_test)}")
print(f"Procent błędów: {len(incorrect_indices)/len(y_test)*100:.2f}%\n")

plt.figure(figsize=(12, 12))
for i in range(min(9, len(incorrect_indices))):
    idx = incorrect_indices[i]
    plt.subplot(3, 3, i + 1)
    plt.imshow(x_test[idx], cmap='gray')
    plt.title(f"Prawda: {y_test[idx]}, Predykcja: {predicted_labels[idx]}",
              color='red')
    plt.axis('off')
plt.suptitle("Przykłady błędnie sklasyfikowanych cyfr", fontsize=16)
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test, predicted_labels)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=range(10), yticklabels=range(10))
plt.xlabel('Predykcja', fontsize=12)
plt.ylabel('Prawdziwa wartość', fontsize=12)
plt.title('Macierz pomyłek', fontsize=14)
plt.show()

print("\nNajczęstsze pomyłki")
for i in range(10):
    for j in range(10):
        if i != j and cm[i][j] > 10:
            print(f"Cyfra {i} mylona z cyfrą {j}: {cm[i][j]} razy")

"""**Wpływ różnych konfiguracji modelu na jego dokładność.**
Liczba epok:

3 epoki → 97.45%
5 epok → 97.84%
10 epok → 97.88%
Wniosek: Więcej epok = lepsza dokładność, ale po 5 epokach poprawa minimalna (0.04%)

Liczba warstw ukrytych:

1 warstwa → 97.84%
2 warstwy → 97.44%
3 warstwy → 97.38%
Wniosek: Więcej warstw = gorsza dokładność! Dla MNIST problem jest prosty, głębsze sieci niepotrzebne.

Liczba neuronów:

64 neurony → 97.37%
128 neuronów → 97.84%
256 neuronów → 97.46%
Wniosek: 128 neuronów optymalne. Za mało (64) = za słaba sieć. Za dużo (256) = przeuczenie.

Zadanie 5:
Co udało się zaobserwować podczas eksperymentów? Jakie zmiany wpływały pozytywnie, a jakie negatywnie?

Pozytywnie wpłynęło:

- 5 epok treningu - dobry balans dokładność/czas
- 128 neuronów - optymalna pojemność sieci
- Prosta architektura (1 warstwa) - najlepsza dla MNIST
- Normalizacja danych (÷255) - szybsze uczenie

Negatywnie wpłynęło:

- Dodawanie warstw - komplikacja bez korzyści
- 64 neurony - za mała pojemność modelu
- 256 neuronów - przeuczenie (overfitting)
- 10 epok - marnowanie czasu bez poprawy wyniku

Trudności:

- Instalacja TensorFlow na Windows (problemy z DLL) ->Rozwiązanie: Google Colab
- Długi czas treningu dla 256 neuronów
- Zaskoczenie, że prostszy model działa lepiej

Zadanie 6: Przeanalizuj dokładność modelu dla poszczególnych klas.

Najlepiej rozpoznawane cyfry:

Cyfra 1: 99.12% - prosta forma
Cyfra 6: 99.27% - charakterystyczny kształt
Cyfra 0: 98.88% - wyraźny okrąg

Najgorzej rozpoznawane cyfry:

Cyfra 9: 95.24% - mylona z cyfrą 4
Cyfra 5: 96.41% - podobna do cyfry 3
Cyfra 8: 97.13% - złożona struktura

Dlaczego model się myli?

Cyfry 9 i 4 mają podobne górne elementy
Cyfry 5 i 3 mają zaokrąglone kształty
Niektóre cyfry nieczytelne nawet dla człowieka (pismo odręczne różne)

Całkowita liczba błędów: 216 z 10,000 (2.16%)
"""

